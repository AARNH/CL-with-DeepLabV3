{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AARNH/CL-with-DeepLabV3/blob/main/pretraining_CL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n"
      ],
      "metadata": {
        "id": "heetwYsXXczD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e90187-559b-45e5-8c2d-8794bcf57250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-01 12:24:50--  https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/246276098/8ae3c180-64bd-11ea-91fe-0f47017fe9be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230901%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230901T122450Z&X-Amz-Expires=300&X-Amz-Signature=0ebce1485fdf53f02e2a394000164cc4082337984af4f5dafdf8c96add300fc6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=246276098&response-content-disposition=attachment%3B%20filename%3Dcheckpoint_100.tar&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-01 12:24:50--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/246276098/8ae3c180-64bd-11ea-91fe-0f47017fe9be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230901%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230901T122450Z&X-Amz-Expires=300&X-Amz-Signature=0ebce1485fdf53f02e2a394000164cc4082337984af4f5dafdf8c96add300fc6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=246276098&response-content-disposition=attachment%3B%20filename%3Dcheckpoint_100.tar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 111607632 (106M) [application/octet-stream]\n",
            "Saving to: ‘checkpoint_100.tar’\n",
            "\n",
            "checkpoint_100.tar  100%[===================>] 106.44M   460MB/s    in 0.2s    \n",
            "\n",
            "2023-09-01 12:24:51 (460 MB/s) - ‘checkpoint_100.tar’ saved [111607632/111607632]\n",
            "\n",
            "Collecting simclr\n",
            "  Downloading simclr-1.0.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from simclr) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from simclr) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from simclr) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->simclr) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->simclr) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->simclr) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->simclr) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->simclr) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->simclr) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->simclr) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->simclr) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->simclr) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->simclr) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->simclr) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->simclr) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->simclr) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->simclr) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->simclr) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->simclr) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->simclr) (1.3.0)\n",
            "Installing collected packages: simclr\n",
            "Successfully installed simclr-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install library\n",
        "!pip install byol-pytorch\n",
        "#Import library dan modul yang diperlukan\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms.functional import resize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "from torch.serialization import save\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.nn.functional import interpolate\n",
        "import random\n",
        "\n",
        "#Mengimpor dataset\n",
        "drive.mount('/content/gdrive')\n",
        "path_file_zip = '/content/gdrive/MyDrive/pretraining.zip'\n",
        "echo_pre = '/content/pre/'\n",
        "\n",
        "# Mengekstrak file zip\n",
        "with zipfile.ZipFile(path_file_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(echo_pre)\n",
        "\n",
        "print(\"File telah diekstrak di:\", echo_pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2zJmmXQXrXc",
        "outputId": "20472f22-ce79-4712-865e-83038823486f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "File telah diekstrak di: /content/pre/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BYOL"
      ],
      "metadata": {
        "id": "FCFcbqHRjE6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from byol_pytorch import BYOL\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# Direktori penyimpanan model\n",
        "save_directory = '/content/gdrive/MyDrive'\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "batch_size = 4\n",
        "temperature = 0.1\n",
        "\n",
        "def save_model(epoch):\n",
        "    # Simpan state dict dari model ResNet-50 saat fungsi dipanggil\n",
        "    resnet_out = os.path.join(save_directory, f'resnet50_state_dict_epoch_{epoch}.pth')\n",
        "    torch.save(resnet.state_dict(), resnet_out)\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        # Convert RGBA to RGB if image has 4 channels\n",
        "        if image.mode == \"RGBA\":\n",
        "            image = image.convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# Transformasi untuk augmentasi data\n",
        "transform_for_training = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Buat dataset dan DataLoader untuk citra echocardiography\n",
        "echocardiography_dataset = CustomDataset(root_dir='/content/pre/pretraining/train',\n",
        "                                         transform=transform_for_training)\n",
        "\n",
        "# Menghitung jumlah data yang akan digunakan (20% dari total data)\n",
        "subset_percentage = 0.2\n",
        "subset_size = int(len(echocardiography_dataset) * subset_percentage)\n",
        "\n",
        "# Membuat Subset dari dataset\n",
        "subset_indices = range(0, subset_size)\n",
        "subset_dataset = Subset(echocardiography_dataset, subset_indices)\n",
        "\n",
        "# Buat DataLoader dari subset data\n",
        "subset_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "# Inisialisasi model ResNet-50\n",
        "resnet = resnet50(pretrained=True)\n",
        "resnet = resnet.to(device)\n",
        "\n",
        "# Inisialisasi model BYOL dengan dua encoder\n",
        "learner = BYOL(resnet,image_size=224,hidden_layer='avgpool',use_momentum=False)\n",
        "learner = learner.to(device)\n",
        "# Inisialisasi optimizer\n",
        "optimizer = torch.optim.Adam(learner.parameters(), lr=3e-4)\n",
        "# Definisikan Early Stopping\n",
        "early_stopping_patience = 3\n",
        "best_loss = float('inf')\n",
        "patience_counter = 0\n",
        "# Melatih model BYOL\n",
        "num_epochs = 100  # Ganti sesuai kebutuhan Anda\n",
        "current_epoch = 0\n",
        "for epoch in range(num_epochs):\n",
        "    learner.train()\n",
        "    loss_epoch = 0.0\n",
        "\n",
        "    for batch in subset_loader:\n",
        "        batch = batch.to(device)\n",
        "        loss = learner(batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_epoch += loss.item()\n",
        "\n",
        "    average_loss = loss_epoch / len(subset_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {average_loss}\")\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        save_model(epoch)\n",
        "    # Validasi Early Stopping\n",
        "    if average_loss < best_loss:\n",
        "        best_loss = average_loss\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(f\"Early Stopping: No improvement in {early_stopping_patience} epochs.\")\n",
        "            break\n",
        "\n",
        "# Simpan model tanpa informasi pelatihan dalam format model.pth\n",
        "torch.save(resnet.state_dict(), os.path.join(save_directory, 'resnet50_state_dict.pth'))"
      ],
      "metadata": {
        "id": "RO5oh8F7RrNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIMCLR"
      ],
      "metadata": {
        "id": "wANBW2Nki7G8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi17mZRLXPve"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from simclr import SimCLR\n",
        "from simclr.modules import get_resnet, NT_Xent\n",
        "from simclr.modules.transformations import TransformsSimCLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "save_directory = '/content/gdrive/MyDrive'\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "batch_size = 4\n",
        "temperature = 0.1\n",
        "# Dataset dan DataLoader untuk citra echocardiography\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        # Convert RGBA menjadi RGB jika gambar memiliki 4 channel\n",
        "        if image.mode == \"RGBA\":\n",
        "            image = image.convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "transformsimclr=TransformsSimCLR(size=224)\n",
        "# Buat dataset dan DataLoader untuk citra echocardiography\n",
        "echocardiography_dataset = CustomDataset(root_dir='/content/pre/pretraining/train',\n",
        "                                         transform=transformsimclr )\n",
        "\n",
        "# Menghitung jumlah data yang akan digunakan (20% dari total data)\n",
        "subset_percentage = 0.2\n",
        "subset_size = int(len(echocardiography_dataset) * subset_percentage)\n",
        "\n",
        "# Membuat Subset dari dataset\n",
        "subset_indices = range(0, subset_size)\n",
        "subset_dataset = Subset(echocardiography_dataset, subset_indices)\n",
        "\n",
        "# Membuat DataLoader dari subset data\n",
        "subset_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# initialize ResNet\n",
        "encoder =  models.resnet50(weights=None)\n",
        "n_features = encoder.fc.in_features  # mengambil dimensi fully connected layer\n",
        "projection_dim = 64\n",
        "# initialize model\n",
        "model = SimCLR(encoder, projection_dim, n_features)\n",
        "if False:\n",
        "    model_fp = os.path.join(\n",
        "        save, \"checkpoint_{}.tar\".format(100)\n",
        "    )\n",
        "    model.load_state_dict(torch.load(model_fp, map_location=device))\n",
        "model = model.to(device)\n",
        "# optimizer / loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = NT_Xent(batch_size, temperature, world_size=1)\n",
        "writer = SummaryWriter()\n",
        "# Fungsi pelatihan\n",
        "def train(subset_loader, model, criterion, optimizer, writer):\n",
        "    loss_epoch = 0\n",
        "    global_step = 0\n",
        "    for step, ((x_i, x_j)) in enumerate(subset_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x_i = x_i.to(device)\n",
        "        x_j = x_j.to(device)\n",
        "\n",
        "        # mencari pasangan positif dengan encoding\n",
        "        h_i, h_j, z_i, z_j = model(x_i, x_j)\n",
        "        loss = criterion(z_i, z_j)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 1000 == 0:\n",
        "            print(f\"Step [{step}/{len(subset_loader)}]\\t Loss: {loss.item()}\")\n",
        "\n",
        "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), global_step)\n",
        "        loss_epoch += loss.item()\n",
        "        global_step += 1\n",
        "    return loss_epoch\n",
        "\n",
        "    def save_model(model, optimizer):\n",
        "    out = os.path.join(save_directory, \"checkpoint_{}.tar\".format(current_epoch))\n",
        "\n",
        "    if isinstance(model, torch.nn.DataParallel):\n",
        "        torch.save(model.module.state_dict(), out)\n",
        "    else:\n",
        "        torch.save(model.state_dict(), out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThURLdNwXPvf"
      },
      "outputs": [],
      "source": [
        "early_stopping_patience = 5\n",
        "best_loss = float('inf')\n",
        "best_epoch = 0\n",
        "early_stopping_counter = 0\n",
        "current_epoch = 0\n",
        "start_epoch = 1\n",
        "epochs = 100\n",
        "scheduler = None\n",
        "for epoch in range(start_epoch, epochs):\n",
        "    lr = optimizer.param_groups[0][\"lr\"]\n",
        "    loss_epoch = train(subset_loader, model, criterion, optimizer, writer)\n",
        "\n",
        "    if scheduler:\n",
        "        scheduler.step()\n",
        "\n",
        "    # save every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        save_model(model, optimizer)\n",
        "\n",
        "    writer.add_scalar(\"Loss/train\", loss_epoch / len(subset_loader), epoch)\n",
        "    writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
        "    print(\n",
        "        f\"Epoch [{epoch}/{epochs}]\\t Loss: {loss_epoch / len(subset_loader)}\\t lr: {round(lr, 5)}\"\n",
        "    )\n",
        "    current_epoch += 1\n",
        "    Loss=loss_epoch / len(subset_loader)\n",
        "    if Loss < best_loss:\n",
        "        best_loss = Loss\n",
        "        best_epoch = epoch\n",
        "        early_stopping_counter = 0\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        if early_stopping_counter >= early_stopping_patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch}.\")\n",
        "            break\n",
        "\n",
        "# Save the best model\n",
        "best_model_filename = f\"final_model_epoch_{best_epoch}.tar\"\n",
        "save_model(model, optimizer)  # Save the best model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "collapsed_sections": [
        "FCFcbqHRjE6E"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}